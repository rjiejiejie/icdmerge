# 3. 处理对角线 (自己到自己的距离是0，倒数是Inf，需要设为0)
diag(inv_d_mat) <- 0
# 4. 计算平均值 (只计算 N*(N-1) 个非对角元素)
n <- vcount(g)
eff <- sum(inv_d_mat) / (n * (n - 1))
return(eff)
}
# 2. 核心计算函数
calculate_advanced_metrics <- function(list_name, file_path) {
message(paste("正在分析效能指标:", list_name, "..."))
# --- A. 数据读取 ---
dt <- fread(file_path, select = c("eid", "Diagnosis_Code", "Category_No"))
dt <- dt[!is.na(Category_No) & Category_No != ""]
dt[, Category_No := as.character(Category_No)]
dt[, Diagnosis_Code := as.character(Diagnosis_Code)]
if(nrow(dt) == 0) return(NULL)
# --- B. 构建基础矩阵 ---
dt[, pid_idx := as.numeric(as.factor(eid))]
dt[, diag_idx := as.numeric(as.factor(Diagnosis_Code))]
code_map <- unique(dt[, .(Diagnosis_Code, Category_No, diag_idx)])
setorder(code_map, diag_idx)
mat <- sparseMatrix(i = dt$pid_idx, j = dt$diag_idx, x = 1)
# =========================================================
# 指标 1: 组内连接模式相似度 (Profile Similarity)
# =========================================================
message("  - 计算组内模式相似度...")
cooccur <- t(mat) %*% mat
profile_cor <- cor(as.matrix(cooccur))
diag(profile_cor) <- NA
groups <- code_map$Category_No
unique_groups <- unique(groups)
group_cor_means <- c()
for(g in unique_groups) {
indices <- which(groups == g)
if(length(indices) > 1) {
sub_mat <- profile_cor[indices, indices]
avg_cor <- mean(sub_mat, na.rm = TRUE)
group_cor_means <- c(group_cor_means, avg_cor)
}
}
avg_within_group_similarity <- mean(group_cor_means, na.rm = TRUE)
# =========================================================
# 指标 2 & 3: 聚合网络指标
# =========================================================
message("  - 计算聚合网络指标...")
dt[, cat_idx := as.numeric(as.factor(Category_No))]
dt_agg <- unique(dt[, .(eid, pid_idx, cat_idx)])
mat_cat <- sparseMatrix(i = dt_agg$pid_idx, j = dt_agg$cat_idx, x = 1)
adj_cat <- t(mat_cat) %*% mat_cat
diag(adj_cat) <- 0
g_macro <- graph_from_adjacency_matrix(adj_cat, mode = "undirected", weighted = TRUE)
weights <- E(g_macro)$weight
if(length(weights) > 0) {
edge_weight_cv <- sd(weights) / mean(weights)
# --- 修复点：手动计算全局效率 ---
# 定义边的距离为 1/权重 (权重越大，距离越近，传播越快)
E(g_macro)$distance <- 1 / weights
global_eff <- get_global_efficiency(g_macro) # 调用上面的自定义函数
} else {
edge_weight_cv <- 0
global_eff <- 0
}
return(data.frame(
List = list_name,
Profile_Similarity = avg_within_group_similarity,
Network_Clarity_CV = edge_weight_cv,
Global_Efficiency = global_eff
))
}
# 3. 执行循环
adv_results_list <- list()
for (name in names(file_list)) {
res <- tryCatch({
calculate_advanced_metrics(name, file_list[[name]])
}, error = function(e) {
message(paste("跳过", name, ":", e$message))
return(NULL)
})
if(!is.null(res)) adv_results_list[[length(adv_results_list)+1]] <- res
}
df_adv <- rbindlist(adv_results_list)
# 4. 打印结果
print("计算结果如下：")
print(df_adv)
# 5. 可视化
p_sim <- ggplot(df_adv, aes(x = reorder(List, -Profile_Similarity), y = Profile_Similarity, fill = List == "本研究")) +
geom_bar(stat = "identity", width = 0.7) +
geom_text(aes(label = sprintf("%.4f", Profile_Similarity)), vjust = -0.5) +
scale_fill_manual(values = c("FALSE" = "grey70", "TRUE" = "#377EB8")) +
labs(title = "列表内部一致性对比 (Profile Similarity)",
subtitle = "指标含义：组内疾病在网络中连接模式的相似度\n数值越高，说明该列表基于'结构等价性'的分类越准确",
y = "平均组内相关系数 (r)", x = NULL) +
theme_minimal(base_family = "my_font") +
theme(legend.position = "none",
axis.text.x = element_text(size = 12, face = "bold"),
plot.title = element_text(face = "bold"))
print(p_sim)
save_dir <- tryCatch(dirname(file_list[[1]]), error = function(e) getwd())
ggsave(file.path(save_dir, "UKB住院_Comparison_Profile_Similarity.pdf"), p_sim, width = 8, height = 6)
message("分析全部完成！结果已保存。")
library(data.table)
library(Matrix)
# =======================================================
# 0. 配置
# =======================================================
base_dir <- "D:/Files/2025年研究/毕业论文/5.网络分析列表/"
diagnosis_path <- paste0(base_dir, "UKB住院数据_映射后.csv")
codebook_path  <- paste0(base_dir, "UKB住院数据_映射后_频率表.csv")
output_dir <- paste0(base_dir, "ConsensusKMeans_PAC_GlobalProfile_FAST_v3_HOMO1_UKB住院")
if(!dir.exists(output_dir)) dir.create(output_dir)
# ---- 数据筛选阈值 ----
PREVALENCE_CUTOFF <- 0.001  # 0.1%
# ---- 共识 / PAC 参数 ----
N_RESAMPLES <- 200
SAMPLE_FRAC <- 0.8
PAC_X1 <- 0.2
PAC_X2 <- 0.8
PAC_NO_MERGE <- 0.10
# ---- 同质块 -> 允许K=1全合并（新增）----
# K=2共识矩阵上三角的 q 分位数 >= tau 即视为同质块
HOMO_Q   <- 0.10   # 10%分位（比min更稳健）
HOMO_TAU <- 0.90   # “几乎完全一致”的阈值
# ---- K 搜索 ----
K_MAX_PER_BLOCK <- 10
KMEANS_NSTART_RESAMPLE <- 5
KMEANS_NSTART_FINAL <- 50
KMEANS_ITMAX <- 100
# ---- 有效抽样次数下限（避免某些k几乎都失败）----
MIN_VALID_FRAC <- 0.5  # 至少有50%的抽样对该k有效，否则该k记为不可用
block_col <- "System_code"
set.seed(123)
# =======================================================
# 工具函数
# =======================================================
row_zscore <- function(X) {
if (!is.matrix(X)) X <- as.matrix(X)
row_means <- rowMeans(X)
Xc <- X - row_means
row_sds <- sqrt(rowMeans(Xc^2))
row_sds[row_sds == 0 | is.na(row_sds)] <- 1
Xz <- Xc / row_sds
Xz[is.na(Xz)] <- 0
Xz
}
cocluster_mat <- function(cluster, k) {
n <- length(cluster)
Z <- sparseMatrix(i = 1:n, j = cluster, x = 1, dims = c(n, k))
C <- tcrossprod(Z)
C <- as.matrix(C)
diag(C) <- 0
C
}
calc_pac <- function(cons_prob, x1 = 0.1, x2 = 0.9) {
vals <- cons_prob[upper.tri(cons_prob, diag = FALSE)]
if (length(vals) == 0) return(NA_real_)
mean(vals > x1 & vals < x2)
}
sanitize_id <- function(x) gsub("[^A-Za-z0-9]+", "_", x)
# 计算 K=2 共识矩阵“同质性分位数”
calc_homo_q <- function(cons_prob, q = 0.1) {
vals <- cons_prob[upper.tri(cons_prob, diag = FALSE)]
if (length(vals) == 0) return(NA_real_)
as.numeric(quantile(vals, probs = q, na.rm = TRUE, names = FALSE, type = 7))
}
# =======================================================
# 1. 数据准备 (按患病率筛选)
# =======================================================
cat("正在加载数据...\n")
raw_data <- fread(diagnosis_path)
codebook  <- fread(codebook_path)
codebook[, No := as.character(No)]
codebook[, (block_col) := as.character(get(block_col))]
total_patients <- uniqueN(raw_data$eid)
min_freq_threshold <- ceiling(total_patients * PREVALENCE_CUTOFF)
cat(sprintf("【筛选统计】\n总人数 (N): %d\n患病率阈值: %.2f%%\n所需最小频次: %d\n",
total_patients, PREVALENCE_CUTOFF * 100, min_freq_threshold))
valid_cb <- codebook[Frequency >= min_freq_threshold]
cat(sprintf("筛选前节点数: %d -> 筛选后节点数: %d\n", nrow(codebook), nrow(valid_cb)))
if(nrow(valid_cb) == 0) stop("错误：筛选后没有剩余节点，请降低阈值或检查数据。")
valid_cb[is.na(get(block_col)) | get(block_col) == "", (block_col) := "Unknown"]
valid_diseases <- valid_cb$No
current_data <- raw_data[Category_No %in% valid_diseases, .(eid, Category_No)]
current_data <- unique(current_data)
current_data[, Category_No := as.character(Category_No)]
lineage_dt <- data.table(
Current_ID = as.character(valid_cb$No),
Original_Codes = valid_cb$Codes,
Original_Names = valid_cb$Names,
Block = valid_cb[[block_col]],
Member_Count = 1
)
lineage_dt[is.na(Block) | Block == "", Block := "Unknown"]
lineage_dt <- unique(lineage_dt, by = "Current_ID")
cat("初始化完成。\n")
# =======================================================
# 2. 构建 M_full（抽样直接抽行）
# =======================================================
cat("\n构建全量稀疏矩阵 M_full...\n")
fixed_nodes <- sort(unique(current_data$Category_No))
n_nodes <- length(fixed_nodes)
node_map_fixed <- data.table(Category_No = fixed_nodes, col_idx = 1:n_nodes)
unique_eids <- sort(unique(current_data$eid))
n_patients <- length(unique_eids)
eid_map <- data.table(eid = unique_eids, row_idx = 1:n_patients)
block_map_dt <- valid_cb[No %in% fixed_nodes, .(Category_No = No, Block = get(block_col))]
block_map_dt <- unique(block_map_dt, by = "Category_No")
block_map_dt <- merge(node_map_fixed, block_map_dt, by = "Category_No", all.x = TRUE)
block_map_dt[is.na(Block) | Block == "", Block := "Unknown"]
tmp_full <- merge(current_data, eid_map, by = "eid")
tmp_full <- merge(tmp_full, node_map_fixed, by = "Category_No")
M_full <- sparseMatrix(
i = tmp_full$row_idx,
j = tmp_full$col_idx,
x = 1,
dims = c(n_patients, n_nodes)
)
cat(sprintf("完成：病人=%d，疾病=%d\n", n_patients, n_nodes))
# =======================================================
# 3. 预处理：block索引、K候选、容器（K>=2）
# =======================================================
cat("\n准备 block 列表与容器...\n")
blocks <- sort(unique(block_map_dt$Block))
blocks <- blocks[blocks != "Unknown"]
n_blocks <- length(blocks)
cat(sprintf("将处理 %d 个 block。\n", n_blocks))
blk_cols_list <- setNames(vector("list", n_blocks), blocks)
blk_ids_list  <- setNames(vector("list", n_blocks), blocks)
Kcand_list    <- setNames(vector("list", n_blocks), blocks)
nblk_list     <- setNames(integer(n_blocks), blocks)
for (blk in blocks) {
dt <- block_map_dt[Block == blk, .(Category_No, col_idx)]
blk_cols_list[[blk]] <- dt$col_idx
blk_ids_list[[blk]]  <- dt$Category_No
nblk <- length(dt$col_idx)
nblk_list[[blk]] <- nblk
if (nblk < 3) {
Kcand_list[[blk]] <- integer(0)
} else {
kmax <- min(K_MAX_PER_BLOCK, nblk - 1)
Kcand_list[[blk]] <- 2:kmax
}
}
# 共识计数 + 有效次数分母
consensus_counts <- setNames(vector("list", n_blocks), blocks)
valid_counts     <- setNames(vector("list", n_blocks), blocks)
for (blk in blocks) {
nblk <- nblk_list[[blk]]
Ks <- Kcand_list[[blk]]
if (length(Ks) == 0) {
consensus_counts[[blk]] <- NULL
valid_counts[[blk]] <- NULL
} else {
consensus_counts[[blk]] <- lapply(Ks, function(k) matrix(0, nblk, nblk))
names(consensus_counts[[blk]]) <- as.character(Ks)
valid_counts[[blk]] <- setNames(as.list(rep(0L, length(Ks))), as.character(Ks))
}
}
# =======================================================
# 4. 主循环：resample 外层 -> block -> K（含kmeans安全检查）
# =======================================================
cat("\n========== Phase 1: Resample -> Block -> K (FAST v3 + HOMO gate) ==========\n")
pb <- txtProgressBar(min = 0, max = N_RESAMPLES, style = 3)
for (t in 1:N_RESAMPLES) {
sampled_rows <- sample.int(n_patients, size = floor(n_patients * SAMPLE_FRAC), replace = FALSE)
M_sub <- M_full[sampled_rows, , drop = FALSE]
for (blk in blocks) {
Ks <- Kcand_list[[blk]]
if (length(Ks) == 0) next
blk_cols <- blk_cols_list[[blk]]
X_blk <- crossprod(M_sub[, blk_cols, drop = FALSE], M_sub)
X_blk <- as.matrix(X_blk)
X_blk <- row_zscore(X_blk)
n_distinct <- nrow(unique(X_blk))
for (k in Ks) {
if (n_distinct < k) next
km <- kmeans(X_blk, centers = k, nstart = KMEANS_NSTART_RESAMPLE, iter.max = KMEANS_ITMAX)
coc <- cocluster_mat(km$cluster, k)
consensus_counts[[blk]][[as.character(k)]] <- consensus_counts[[blk]][[as.character(k)]] + coc
valid_counts[[blk]][[as.character(k)]] <- valid_counts[[blk]][[as.character(k)]] + 1L
}
}
setTxtProgressBar(pb, t)
}
close(pb)
cat("\n抽样完成，开始计算每个 block 的 PAC(K) 并选 K*（并加同质块K=1门控）...\n")
# =======================================================
# 5. PAC曲线 + 选K*（新增：同质块 -> 允许K=1全合并）
# =======================================================
pac_curves <- list()
kstar_summary <- list()
final_membership_list <- list()
min_valid_n <- ceiling(N_RESAMPLES * MIN_VALID_FRAC)
for (blk in blocks) {
nblk <- nblk_list[[blk]]
ids <- blk_ids_list[[blk]]
Ks <- Kcand_list[[blk]]
# 默认：不允许K=1合并
merge_all <- FALSE
homo_q2 <- NA_real_
valid_n2 <- NA_integer_
# 小block：直接不合并（你也可以日后另加“二元合并”策略）
if (nblk < 3 || length(Ks) == 0) {
final_membership_list[[blk]] <- setNames(rep(1L, nblk), ids)
pac_curves[[blk]] <- data.table(Block = blk, K = NA_integer_, PAC = NA_real_, valid_n = NA_integer_,
n_nodes = nblk, K_star = 1L)
kstar_summary[[blk]] <- data.table(Block = blk, n_nodes = nblk, K_star = 1L,
PAC_min = NA_real_, MergeAll = FALSE,
HomoQ2 = homo_q2, ValidN2 = valid_n2)
next
}
# ---- 先计算 PAC(K) 曲线 ----
pac_dt <- rbindlist(lapply(Ks, function(k) {
vn <- valid_counts[[blk]][[as.character(k)]]
if (is.null(vn) || vn < min_valid_n) {
data.table(K = k, PAC = NA_real_, valid_n = vn)
} else {
cnt <- consensus_counts[[blk]][[as.character(k)]]
prob <- cnt / vn
data.table(K = k, PAC = calc_pac(prob, PAC_X1, PAC_X2), valid_n = vn)
}
}))
pac_dt[, Block := blk]
pac_dt[, n_nodes := nblk]
# ---- 同质块门控：看 K=2 的共识矩阵是否“几乎全一致” ----
# 只有当 K=2 在候选中且有效次数足够时才判
if ("2" %in% names(consensus_counts[[blk]])) {
valid_n2 <- valid_counts[[blk]][["2"]]
if (!is.null(valid_n2) && valid_n2 >= min_valid_n) {
prob2 <- consensus_counts[[blk]][["2"]] / valid_n2
homo_q2 <- calc_homo_q(prob2, q = HOMO_Q)
if (!is.na(homo_q2) && homo_q2 >= HOMO_TAU) {
merge_all <- TRUE
}
}
}
# ---- 选K*：如果同质块，则K*=1且允许全合并；否则走PAC选K（K>=2） ----
if (merge_all) {
K_star <- 1L
pac_min <- min(pac_dt$PAC, na.rm = TRUE)  # 记录一下不影响
} else {
if (all(is.na(pac_dt$PAC))) {
K_star <- 1L
pac_min <- NA_real_
} else {
pac_min <- min(pac_dt$PAC, na.rm = TRUE)
if (is.na(pac_min) || pac_min > PAC_NO_MERGE) {
K_star <- 1L
} else {
eps <- 0.01
cand <- pac_dt[!is.na(PAC) & PAC <= pac_min + eps, K]
K_star <- min(cand)
}
}
}
pac_dt[, K_star := K_star]
pac_curves[[blk]] <- pac_dt
kstar_summary[[blk]] <- data.table(
Block = blk, n_nodes = nblk, K_star = K_star,
PAC_min = pac_min, MergeAll = merge_all,
HomoQ2 = homo_q2, ValidN2 = valid_n2
)
# ---- 最终 membership：若 K*=1 且 merge_all=TRUE，后面会把全块合并 ----
if (K_star == 1L) {
final_membership_list[[blk]] <- setNames(rep(1L, nblk), ids)
} else {
blk_cols <- blk_cols_list[[blk]]
X_full_blk <- crossprod(M_full[, blk_cols, drop = FALSE], M_full)
X_full_blk <- as.matrix(X_full_blk)
X_full_blk <- row_zscore(X_full_blk)
if (nrow(unique(X_full_blk)) < K_star) {
final_membership_list[[blk]] <- setNames(rep(1L, nblk), ids)
kstar_summary[[blk]][, `:=`(K_star = 1L, MergeAll = FALSE)]
pac_dt[, K_star := 1L]
} else {
km_full <- kmeans(X_full_blk, centers = K_star, nstart = KMEANS_NSTART_FINAL, iter.max = 200)
cl <- km_full$cluster
names(cl) <- ids
final_membership_list[[blk]] <- cl
}
}
}
pac_all <- rbindlist(pac_curves, fill = TRUE)
kstar_all <- rbindlist(kstar_summary, fill = TRUE)
fwrite(pac_all,  file.path(output_dir, "PAC_Curves_ByBlock.csv"))
fwrite(kstar_all, file.path(output_dir, "PAC_Summary_Kstar.csv"))
membership_dt <- rbindlist(lapply(names(final_membership_list), function(blk) {
cl <- final_membership_list[[blk]]
data.table(Block = blk, Disease = names(cl), Cluster = as.integer(cl))
}), fill = TRUE)
fwrite(membership_dt, file.path(output_dir, "Final_Block_Memberships.csv"))
cat("K* 已选定，开始根据最终簇进行 block 内合并（含同质块K=1全合并）...\n")
# =======================================================
# 7. 合并（两种情况）
#   A) K*>1: 按簇合并
#   B) K*=1 且 MergeAll=TRUE: 全块合并成1个节点
# =======================================================
update_map <- data.table(Old_ID = character(), New_ID = character())
for (blk in names(final_membership_list)) {
row <- kstar_all[Block == blk]
if (nrow(row) == 0) next
K_star <- row$K_star[1]
merge_all <- isTRUE(row$MergeAll[1])
cl <- final_membership_list[[blk]]
if (length(cl) < 2) next
if (K_star > 1L) {
clusters <- split(names(cl), cl)
for (cid in names(clusters)) {
members <- clusters[[cid]]
if (length(members) <= 1) next
old_records <- lineage_dt[Current_ID %in% members]
if (nrow(old_records) == 0) next
leader_code <- old_records$Original_Codes[1]
prefix <- strsplit(leader_code, "\\|")[[1]][1]
blk_safe <- sanitize_id(blk)
new_id <- paste0(prefix, "_", blk_safe, "_K", K_star, "_C", cid, "_Merged")
update_map <- rbind(update_map, data.table(Old_ID = members, New_ID = new_id), fill = TRUE)
new_entry <- data.table(
Current_ID = new_id,
Original_Codes = paste(old_records$Original_Codes, collapse = "|"),
Original_Names = paste(old_records$Original_Names, collapse = "|"),
Block = blk,
Member_Count = sum(old_records$Member_Count)
)
lineage_dt <- lineage_dt[!Current_ID %in% members]
lineage_dt <- rbind(lineage_dt, new_entry, fill = TRUE)
}
} else if (K_star == 1L && merge_all) {
# ✅ 同质块：全块合并为一个节点
members <- names(cl)
old_records <- lineage_dt[Current_ID %in% members]
if (nrow(old_records) > 0 && length(members) > 1) {
leader_code <- old_records$Original_Codes[1]
prefix <- strsplit(leader_code, "\\|")[[1]][1]
blk_safe <- sanitize_id(blk)
new_id <- paste0(prefix, "_", blk_safe, "_K1_AllMerged")
update_map <- rbind(update_map, data.table(Old_ID = members, New_ID = new_id), fill = TRUE)
new_entry <- data.table(
Current_ID = new_id,
Original_Codes = paste(old_records$Original_Codes, collapse = "|"),
Original_Names = paste(old_records$Original_Names, collapse = "|"),
Block = blk,
Member_Count = sum(old_records$Member_Count)
)
lineage_dt <- lineage_dt[!Current_ID %in% members]
lineage_dt <- rbind(lineage_dt, new_entry, fill = TRUE)
}
}
}
if (nrow(update_map) > 0) {
current_data[, Category_No := as.character(Category_No)]
to_chg <- current_data[Category_No %in% update_map$Old_ID]
unchg  <- current_data[!Category_No %in% update_map$Old_ID]
if (nrow(to_chg) > 0) {
to_chg <- merge(to_chg, update_map, by.x = "Category_No", by.y = "Old_ID", all.x = TRUE)
to_chg[, Category_No := New_ID][, New_ID := NULL]
}
current_data <- rbind(unchg, to_chg, fill = TRUE)
current_data <- unique(current_data)
} else {
cat("没有发现需要合并的簇（可能多数 block K*=1 且未触发同质块门控）。\n")
}
# =======================================================
# 8. 保存
# =======================================================
cat("\n保存最终结果...\n")
fwrite(current_data, file.path(output_dir, "Final_Merged_Data.csv"))
fwrite(lineage_dt,  file.path(output_dir, "Final_Merged_Dict.csv"))
fwrite(update_map,  file.path(output_dir, "Merge_Update_Map.csv"))
cat(sprintf("\n=== 处理完成 ===\n"))
cat(sprintf("最终节点数: %d\n", uniqueN(current_data$Category_No)))
cat(sprintf("合并组数: %d\n", nrow(lineage_dt[Member_Count > 1])))
cat(sprintf("结果已保存至: %s\n", output_dir))
install.packages(c("devtools","usethis","roxygen2","testthat"))
usethis::create_package("icdmerge")
install.packages("usethis")
options(repos = c(CRAN = "https://cloud.r-project.org/"))
# 2. 如果是Windows，检查是否已安装Rtools
#    未安装的话下载：https://cran.r-project.org/bin/windows/Rtools/
#    安装后重启R/RStudio
# 3. 重新安装
install.packages("usethis", dependencies = TRUE)
# 1. 设置国内CRAN镜像（如清华源）
options(repos = c(CRAN = "https://cloud.r-project.org/"))
# 2. 如果是Windows，检查是否已安装Rtools
#    未安装的话下载：https://cran.r-project.org/bin/windows/Rtools/
#    安装后重启R/RStudio
# 3. 重新安装
install.packages("usethis", dependencies = TRUE)
# 在全新R会话中运行
lock_path <- "D:/Research/R/R-4.3.3/library/00LOCK-cli"
if (dir.exists(lock_path)) {
unlink(lock_path, recursive = TRUE)
message("已删除cli的LOCK文件夹")
}
lock_path <- "D:/Research/R/R-4.3.3/library/00LOCK-rlang"
if (dir.exists(lock_path)) {
unlink(lock_path, recursive = TRUE)
message("已删除rlang的LOCK文件夹")
}
# 优先安装二进制版本（不要编译源码）
options(install.packages.compile.from.source = "never")
# 逐个安装，每步确认成功后再继续
install.packages("cli", type = "binary")
install.packages("rlang", type = "binary")
install.packages("gert", type = "binary")
# 最后安装usethis
install.packages("usethis", type = "binary")
install.packages("cli", type = "binary")
install.packages("gert", type = "binary")
install.packages("usethis", type = "binary")
usethis::create_package("icdmerge")
setwd("icdmerge")
